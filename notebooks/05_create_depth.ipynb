{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c346121a-0596-4a79-93b6-fbda8a66bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae6d699-5310-4ea7-9db6-f77558451c1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scale_to_z(a, min_depth, max_depth, dtype=np.uint8):\n",
    "    \"\"\" Scales an array of values from specified min, max range to 0-z_scale\n",
    "        Optionally specify the data type of the output (default is uint16)\n",
    "    \"\"\"\n",
    "    bg_mask = np.full(a.shape, 255)\n",
    "    img = (((a - min_depth) / float(max_depth - min_depth)) * 254)\n",
    "    depth_img = np.where(a == np.inf, bg_mask, img)\n",
    "    # print(np.sum(a == z_bg))\n",
    "    \n",
    "    return depth_img.astype(dtype)\n",
    "\n",
    "def scale_to_z_v2(a, max_z_distance, dtype=np.uint8):\n",
    "    \"\"\" Scales an array of values from specified min, max range to 0-z_scale\n",
    "        Optionally specify the data type of the output (default is uint16)\n",
    "    \"\"\"\n",
    "    bg_mask = np.full(a.shape, 255)\n",
    "    img = (((a - 0) / float(max_z_distance - 0)) * 254)\n",
    "    depth_img = np.where(a == np.inf, bg_mask, img)\n",
    "    # print(np.sum(a == z_bg))\n",
    "    return depth_img.astype(dtype)\n",
    "\n",
    "def get_spatial_limit_of_point_cloud(pc_mesh):\n",
    "    np_vertices = np.asarray(pc_mesh.vertices)\n",
    "    x_max = np.max(np_vertices[:, 0])\n",
    "    x_min = np.min(np_vertices[:, 0])\n",
    "    y_max = np.max(np_vertices[:, 1])\n",
    "    y_min = np.min(np_vertices[:, 1])\n",
    "    z_min = np.min(np_vertices[:, 2])\n",
    "    z_max = np.max(np_vertices[:, 2])\n",
    "    spatial_limit = {'x_max': x_max, 'x_min': x_min, 'y_max': y_max, 'y_min': y_min, 'z_min': z_min, 'z_max': z_max}\n",
    "    return spatial_limit\n",
    "\n",
    "# create depthmap with ray tracing, z-min and z-max will be changed in every single characters \n",
    "def ray_tracing_depth_map(pc_mesh, \n",
    "                          side_range=(-9, 9), \n",
    "                          fwd_range=(-9, 9), \n",
    "                          res=(16000, 16000, 255),\n",
    "                          z_camera=4):\n",
    "    \"\"\"Creates an depth map image with ray tracing (ray casting) technique.\n",
    "    Args:\n",
    "        pc_mesh: mesh of sino-nom character\n",
    "        side_range: (tuple of two floats)\n",
    "                    (-left, right) in metres\n",
    "                    left and right limits of rectangle to look at.\n",
    "        fwd_range:  (tuple of two floats)\n",
    "                    (-behind, front) in metres\n",
    "                    back and front limits of rectangle to look at.\n",
    "        res:        (int, int, float) desired resolution in metres to use\n",
    "    Returns:\n",
    "        depth_map img\n",
    "    \"\"\"\n",
    "    # Create a scene and add the triangle mesh\n",
    "    t_pc_mesh = o3d.t.geometry.TriangleMesh.from_legacy(pc_mesh)\n",
    "    scene = o3d.t.geometry.RaycastingScene()\n",
    "    character_id = scene.add_triangles(t_pc_mesh)\n",
    "    side_width = side_range[1] - side_range[0]\n",
    "    fwd_height = fwd_range[1] - fwd_range[0]\n",
    "    ratio_width = side_width / res[0]\n",
    "    ratio_height = fwd_height / res[1]\n",
    "    x_range = side_range[0] + np.arange(res[0])*ratio_width\n",
    "    y_range = fwd_range[0] + np.arange(res[1])*ratio_height\n",
    "    x_mesh, y_mesh = np.meshgrid(x_range, y_range)\n",
    "    x_mesh_flat = x_mesh.reshape((-1, ))\n",
    "    y_mesh_flat = y_mesh.reshape((-1, ))\n",
    "    z_mesh_flat = np.full((x_mesh_flat.shape[0], ), z_camera)\n",
    "    direction = np.repeat(np.asarray([0, 0, -1]).reshape((1, -1)), z_mesh_flat.shape[0], axis=0)\n",
    "    point_mesh = np.stack((x_mesh_flat, y_mesh_flat, z_mesh_flat), axis=1)\n",
    "    rays = np.concatenate((point_mesh, direction), axis=1)\n",
    "    rays = o3d.core.Tensor(rays, dtype=o3d.core.Dtype.Float32)\n",
    "    ans = scene.cast_rays(rays)\n",
    "    pixel_values = ans['t_hit'].numpy()\n",
    "    pixel_values = pixel_values.reshape((res[0], res[1]))\n",
    "    _, z_max_depth = -np.sort(-np.unique(pixel_values))[:2]\n",
    "    z_min_depth = np.min(pixel_values)\n",
    "    \n",
    "    normalized_pixel_values = scale_to_z(pixel_values, z_min_depth, z_max_depth)\n",
    "    img_inverted_matrix = np.array([[ratio_width, 0, 0, side_range[0]], [0, ratio_height, 0, fwd_range[0]], [0, 0, -(z_max_depth - z_min_depth)/res[2],z_camera - z_min_depth], [0, 0, 0, 1]])\n",
    "    return img_inverted_matrix, normalized_pixel_values\n",
    "\n",
    "\n",
    "def ray_tracing_depth_map_v2(pc_mesh, side_range=(-12, 12), fwd_range=(-12, 12), res=(2000, 2000, 255), z_max_camera=10, max_z_distance=16):\n",
    "    t_pc_mesh = o3d.t.geometry.TriangleMesh.from_legacy(pc_mesh)\n",
    "    scene = o3d.t.geometry.RaycastingScene()\n",
    "    character_id = scene.add_triangles(t_pc_mesh)\n",
    "    side_width = side_range[1] - side_range[0]\n",
    "    fwd_height = fwd_range[1] - fwd_range[0]\n",
    "    ratio_width = side_width / res[0]\n",
    "    ratio_height = fwd_height / res[1]\n",
    "    x_range = side_range[0] + np.arange(res[0])*ratio_width\n",
    "    y_range = fwd_range[0] + np.arange(res[1])*ratio_height\n",
    "    x_mesh, y_mesh = np.meshgrid(x_range, y_range)\n",
    "    x_mesh_flat = x_mesh.reshape((-1, ))\n",
    "    y_mesh_flat = y_mesh.reshape((-1, ))\n",
    "    z_mesh_flat = np.full((x_mesh_flat.shape[0], ), z_max_camera)\n",
    "    direction = np.repeat(np.asarray([0, 0, -1]).reshape((1, -1)), z_mesh_flat.shape[0], axis=0)\n",
    "    point_mesh = np.stack((x_mesh_flat, y_mesh_flat, z_mesh_flat), axis=1)\n",
    "    rays = np.concatenate((point_mesh, direction), axis=1)\n",
    "    rays = o3d.core.Tensor(rays, dtype=o3d.core.Dtype.Float32)\n",
    "    ans = scene.cast_rays(rays)\n",
    "    pixel_values = ans['t_hit'].numpy()\n",
    "    pixel_values = pixel_values.reshape((res[0], res[1]))\n",
    "    _, z_max_depth = -np.sort(-np.unique(pixel_values))[:2]\n",
    "    \n",
    "    z_min_depth = np.min(pixel_values)\n",
    "    # normalized_pixel_values = scale_to_z_v2(pixel_values, max_z_distance)\n",
    "    normalized_pixel_values = scale_to_z(pixel_values, z_min_depth, z_max_depth)\n",
    "    img_inverted_matrix = np.array([[ratio_width, 0, 0, side_range[0]], [0, ratio_height, 0, fwd_range[0]], [0, 0, -max_z_distance/254.0, z_max_camera], [0, 0, 0, 1]])\n",
    "    return img_inverted_matrix, normalized_pixel_values\n",
    "\n",
    "def convert_pc_to_depth_map_v2(stl_path):\n",
    "    pc_mesh = o3d.io.read_triangle_mesh(stl_path)\n",
    "    spatial_limit = get_spatial_limit_of_point_cloud(pc_mesh)\n",
    "    y_length = spatial_limit[\"y_max\"] - spatial_limit[\"y_min\"]\n",
    "    x_length = spatial_limit[\"x_max\"] - spatial_limit[\"x_min\"]\n",
    "    print(spatial_limit)\n",
    "    if y_length > x_length:\n",
    "        x_need = (y_length - x_length) / 2\n",
    "        spatial_limit[\"x_min\"] -= x_need\n",
    "        spatial_limit[\"x_max\"] += x_need\n",
    "    else:\n",
    "        y_need = (x_length - y_length) / 2\n",
    "        spatial_limit[\"y_min\"] -= y_need\n",
    "        spatial_limit[\"y_max\"] += y_need\n",
    "    img_inverted_matrix, normalized_depth_img = ray_tracing_depth_map_v2(pc_mesh,  side_range=(spatial_limit[\"x_min\"], spatial_limit[\"x_max\"]), fwd_range=(spatial_limit[\"y_min\"], spatial_limit[\"y_max\"]), res=(12000, 12000, 255), z_max_camera=spatial_limit[\"z_max\"] + 0.5, max_z_distance=spatial_limit[\"z_max\"] - spatial_limit[\"z_min\"] + 1)\n",
    "\n",
    "    return img_inverted_matrix, normalized_depth_img\n",
    "\n",
    "def run_v2(stl_dir_path, depth_dest_dir, matrix_dest_dir):\n",
    "    stl_file_path_list = list(Path(stl_dir_path).glob(\"*.stl\"))\n",
    "    for stl_file_path in tqdm(stl_file_path_list):\n",
    "        stl_file_stem = stl_file_path.stem\n",
    "        # print(stl_file_stem)\n",
    "        img_depth_path = os.path.join(depth_dest_dir, f'{stl_file_stem}.png')\n",
    "        matrix_path = os.path.join(matrix_dest_dir, f'{stl_file_stem}.npy')\n",
    "        img_inverted_matrix, depth_img = convert_pc_to_depth_map_v2(str(stl_file_path))\n",
    "        cv2.imwrite(str(img_depth_path), depth_img)\n",
    "        np.save(matrix_path, img_inverted_matrix)\n",
    "        \n",
    "# stl_dir_path = \"/mnt/hdd/thuonglc/mocban/reconst_3d/dataset/stl/24539_norm_stl/24539_r\"\n",
    "# depth_dest_dir = '/mnt/hdd/thuonglc/mocban/reconst_3d/dataset/stl/depthmap/depth_imgs'\n",
    "# matrix_dest_dir = '/mnt/hdd/thuonglc/mocban/reconst_3d/dataset/stl/depthmap/inverted_matrix'\n",
    "# Path(depth_dest_dir).mkdir(exist_ok=True)\n",
    "# Path(matrix_dest_dir).mkdir(exist_ok=True)\n",
    "# run_v2(stl_dir_path, depth_dest_dir, matrix_dest_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f126541d-730e-4db0-add4-61b4c1f27e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_max': 136.33131408691406, 'x_min': -153.0210418701172, 'y_max': 111.80522155761719, 'y_min': -97.90929412841797, 'z_min': -2.1585934162139893, 'z_max': 8.019245147705078}\n"
     ]
    }
   ],
   "source": [
    "stl_path = \"/mnt/hdd/thuonglc/mocban/taming-transformers/data/woodblock_components/29141_kho_khuon_in_1_r.stl\"\n",
    "img_inverted_matrix, normalized_depth_img = convert_pc_to_depth_map_v2(stl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e7458d-b6d5-4685-a43d-8225ca4be608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalized_depth_img\n",
    "cv2.imwrite(\"./depth_full.png\", normalized_depth_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e96b65",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plt.imshow(normalized_depth_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fffab6b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stl_r_dir_path = \"/mnt/hdd/thuonglc/mocban/taming-transformers/data/woodblock_components/kho_khuon_in_dataset/kho_khuon_in_r/\"\n",
    "stl_r_path_list = list(Path(stl_r_dir_path).glob(\"*.stl\"))\n",
    "dest_depth_dir = \"/mnt/hdd/thuonglc/mocban/taming-transformers/data/woodblock_components/kho_khuon_in_dataset/depth_2/\"\n",
    "Path(dest_depth_dir).mkdir(exist_ok=True, parents=True)\n",
    "for stl_path in tqdm(stl_r_path_list):\n",
    "    stl_name = stl_path.stem\n",
    "    img_inverted_matrix, normalized_depth_img = convert_pc_to_depth_map_v2(str(stl_path))\n",
    "    # normalized_depth_img\n",
    "    cv2.imwrite(f\"{dest_depth_dir}/{stl_name}_depth.png\", normalized_depth_img)\n",
    "    np.save(f\"{dest_depth_dir}/{stl_name}_matrix.png\", img_inverted_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}